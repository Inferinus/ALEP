{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795aa846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gridspec' from 'matplotlib' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmso\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/missingno/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bar\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m heatmap\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/missingno/missingno.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gridspec\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gridspec' from 'matplotlib' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import missingno as mso\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee50b9e-55b5-49d6-8227-9ebfc48a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a400a",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78faad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/loan_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462db92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Loan_ID.value_counts(dropna=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d8f84",
   "metadata": {},
   "source": [
    "**Note:** 614 unique observations are available in this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f576836",
   "metadata": {},
   "source": [
    "#### GENDER DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Gender\", data=df, hue=\"Gender\", palette=\"hls\")\n",
    "plt.legend().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f97a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "countMale = len(df[df.Gender == 'Male'])\n",
    "countFemale = len(df[df.Gender == 'Female'])\n",
    "countNull = len(df[df.Gender.isnull()])\n",
    "\n",
    "print(\"Percentage of Male applicant: {:.2f}%\".format((countMale / (len(df.Gender))*100)))\n",
    "print(\"Percentage of Female applicant: {:.2f}%\".format((countFemale / (len(df.Gender))*100)))\n",
    "print(\"Missing values percentage: {:.2f}%\".format((countNull / (len(df.Gender))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d027e66",
   "metadata": {},
   "source": [
    "#### Marriage Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7818aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Married.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Married\", data=df, hue=\"Married\", palette=\"Paired\")\n",
    "plt.legend().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307327b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "countMarried = len(df[df.Married == 'Yes'])\n",
    "countNotMarried = len(df[df.Married == 'No'])\n",
    "countNull = len(df[df.Married.isnull()])\n",
    "\n",
    "print(\"Percentage of married: {:.2f}%\".format((countMarried / (len(df.Married))*100)))\n",
    "print(\"Percentage of Not married applicant: {:.2f}%\".format((countNotMarried / (len(df.Married))*100)))\n",
    "print(\"Missing values percentage: {:.2f}%\".format((countNull / (len(df.Married))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676b672",
   "metadata": {},
   "source": [
    "#### Credit History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Credit_History.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Credit_History\", data=df, hue=\"Credit_History\", palette=\"viridis\")\n",
    "plt.legend().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = len(df[df.Credit_History == 1])\n",
    "count0 = len(df[df.Credit_History == 0])\n",
    "countNull = len(df[df.Credit_History.isnull()])\n",
    "\n",
    "print(\"Percentage of Good credit history: {:.2f}%\".format((count1 / (len(df.Credit_History))*100)))\n",
    "print(\"Percentage of Bad credit history: {:.2f}%\".format((count0 / (len(df.Credit_History))*100)))\n",
    "print(\"Missing values percentage: {:.2f}%\".format((countNull / (len(df.Credit_History))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3f967",
   "metadata": {},
   "source": [
    "### Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Loan_Status.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Loan_Status\", data=df, hue=\"Loan_Status\", palette=\"YlOrBr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcac785",
   "metadata": {},
   "outputs": [],
   "source": [
    "countY = len(df[df.Loan_Status == 'Y'])\n",
    "countN = len(df[df.Loan_Status == 'N'])\n",
    "countNull = len(df[df.Loan_Status.isnull()])\n",
    "\n",
    "print(\"Percentage of Approved: {:.2f}%\".format((countY / (len(df.Loan_Status))*100)))\n",
    "print(\"Percentage of Rejected: {:.2f}%\".format((countN / (len(df.Loan_Status))*100)))\n",
    "print(\"Missing values percentage: {:.2f}%\".format((countNull / (len(df.Loan_Status))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6b6ef",
   "metadata": {},
   "source": [
    "#### Loan Amount Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472121e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Loan_Amount_Term.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Loan_Amount_Term\", data=df, hue='Loan_Amount_Term', palette=\"rocket\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count12 = len(df[df.Loan_Amount_Term == 12.0])\n",
    "count36 = len(df[df.Loan_Amount_Term == 36.0])\n",
    "count60 = len(df[df.Loan_Amount_Term == 60.0])\n",
    "count84 = len(df[df.Loan_Amount_Term == 84.0])\n",
    "count120 = len(df[df.Loan_Amount_Term == 120.0])\n",
    "count180 = len(df[df.Loan_Amount_Term == 180.0])\n",
    "count240 = len(df[df.Loan_Amount_Term == 240.0])\n",
    "count300 = len(df[df.Loan_Amount_Term == 300.0])\n",
    "count360 = len(df[df.Loan_Amount_Term == 360.0])\n",
    "count480 = len(df[df.Loan_Amount_Term == 480.0])\n",
    "countNull = len(df[df.Loan_Amount_Term.isnull()])\n",
    "\n",
    "print(\"Percentage of 12: {:.2f}%\".format((count12 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 36: {:.2f}%\".format((count36 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 60: {:.2f}%\".format((count60 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 84: {:.2f}%\".format((count84 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 120: {:.2f}%\".format((count120 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 180: {:.2f}%\".format((count180 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 240: {:.2f}%\".format((count240 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 300: {:.2f}%\".format((count300 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 360: {:.2f}%\".format((count360 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Percentage of 480: {:.2f}%\".format((count480 / (len(df.Loan_Amount_Term))*100)))\n",
    "print(\"Missing values percentage: {:.2f}%\".format((countNull / (len(df.Loan_Amount_Term))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ab1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "sns.histplot(data=df, x=\"ApplicantIncome\", kde=True, ax=axs[0, 0], color='green')\n",
    "sns.histplot(data=df, x=\"CoapplicantIncome\", kde=True, ax=axs[0, 1], color='skyblue')\n",
    "sns.histplot(data=df, x=\"LoanAmount\", kde=True, ax=axs[1, 0], color='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b0061",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ad84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Loan_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ba408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing Categorical values with an estimated value using mode().\n",
    "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
    "df['Married'] = df['Married'].fillna(df['Married'].mode()[0])\n",
    "df['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])\n",
    "df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])\n",
    "df['Credit_History'] = df['Credit_History'].fillna(df['Credit_History'].mode()[0])\n",
    "df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces missing numerical value with an estimated value using mean().\n",
    "df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Drop columns\n",
    "df = df.drop(['Gender_Female', 'Married_No', 'Education_Not Graduate', \n",
    "              'Self_Employed_No', 'Loan_Status_N'], axis = 1)\n",
    "\n",
    "# Rename columns name\n",
    "new = {'Gender_Male': 'Gender', 'Married_Yes': 'Married', \n",
    "       'Education_Graduate': 'Education', 'Self_Employed_Yes': 'Self_Employed',\n",
    "       'Loan_Status_Y': 'Loan_Status'}\n",
    "       \n",
    "df.rename(columns=new, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out the outliers based on the interquartile range (IQR).\n",
    "Q1 = np.percentile(df, 25, axis=0)\n",
    "Q3 = np.percentile(df, 75, axis=0)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19109a",
   "metadata": {},
   "source": [
    "#### Skewed Distribution Treatment\n",
    "In data exploration section, it already shown that distribution for ApplicantIncome, CoapplicantIncome, and LoanAmount is positively skewed.\n",
    "I will use square root transformation to normalized the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aaab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square Root Transformation with dtype casting using loc\n",
    "df.loc[:, 'ApplicantIncome'] = df['ApplicantIncome'].apply(lambda x: np.sqrt(x).astype(float))\n",
    "df.loc[:, 'CoapplicantIncome'] = df['CoapplicantIncome'].apply(lambda x: np.sqrt(x).astype(float))\n",
    "df.loc[:, 'LoanAmount'] = df['LoanAmount'].apply(lambda x: np.sqrt(x).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958211a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "sns.histplot(data=df, x=\"ApplicantIncome\", kde=True, ax=axs[0, 0], color='green')\n",
    "sns.histplot(data=df, x=\"CoapplicantIncome\", kde=True, ax=axs[0, 1], color='skyblue')\n",
    "sns.histplot(data=df, x=\"LoanAmount\", kde=True, ax=axs[1, 0], color='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6fc14",
   "metadata": {},
   "source": [
    "As can be seen, the distribution after using log transformation are much better compared to original distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780ad84",
   "metadata": {},
   "source": [
    "##### Feature Seperating and SMOTE for imbalanced Loan Status counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Separating\n",
    "X = df.drop([\"Loan_Status\"], axis=1)\n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# Value counts for y (Loan_Status)\n",
    "print(\"Value counts for y:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = SMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(y=y, palette=\"coolwarm\")\n",
    "plt.ylabel('Loan Status')\n",
    "plt.xlabel('Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply MinMaxScaler to the training set\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted scaler to a file\n",
    "dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9ae7b",
   "metadata": {},
   "source": [
    "# Models (Ascending accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df2d7b",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier\n",
    "LRclassifier = LogisticRegression(solver='saga', max_iter=500, random_state=1)\n",
    "LRclassifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Apply the same scaling to the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the scaled test set\n",
    "y_pred = LRclassifier.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the accuracy for the test set\n",
    "LRAcc = accuracy_score(y_test, y_pred)\n",
    "print('LR accuracy on the test set: {:.2f}%'.format(LRAcc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594be83",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df003550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Random Forest classifier\n",
    "RFclassifier = RandomForestClassifier(n_estimators=1000, random_state=1)\n",
    "RFclassifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the scaled test set\n",
    "y_pred_rf = RFclassifier.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Calculate and print the accuracy for the test set\n",
    "RFAcc = accuracy_score(y_test, y_pred_rf)\n",
    "print('Random Forest accuracy on the test set: {:.2f}%'.format(RFAcc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(RFclassifier, 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a681b3b",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda419f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data is in a C-contiguous array format\n",
    "X_train_contiguous = np.ascontiguousarray(X_train_scaled)\n",
    "X_test_contiguous = np.ascontiguousarray(X_test_scaled)\n",
    "\n",
    "scoreListknn = []\n",
    "for i in range(1, 21):\n",
    "    KNclassifier = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNclassifier.fit(X_train_contiguous, y_train)\n",
    "    scoreListknn.append(KNclassifier.score(X_test_contiguous, y_test))\n",
    "\n",
    "plt.plot(range(1, 21), scoreListknn)\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n",
    "KNAcc = max(scoreListknn)\n",
    "print(\"KNN best accuracy: {:.2f}%\".format(KNAcc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = scoreListknn.index(max(scoreListknn)) + 1  # Adding 1 because index 0 corresponds to k=1\n",
    "\n",
    "# Train the KNN classifier with the optimal number of neighbors\n",
    "KNclassifier_optimal = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "KNclassifier_optimal.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the scaled test set\n",
    "y_pred_knn = KNclassifier_optimal.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(\"Classification Report for KNN with k =\", optimal_k)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Calculate and print the accuracy for the test set\n",
    "KNAcc_optimal = accuracy_score(y_test, y_pred_knn)\n",
    "print('KNN accuracy on the test set with k = {}: {:.2f}%'.format(optimal_k, KNAcc_optimal * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c6bd8",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclassifier2 = GaussianNB()\n",
    "NBclassifier2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = NBclassifier2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "NBAcc2 = accuracy_score(y_pred,y_test)\n",
    "print('Gaussian Naive Bayes accuracy: {:.2f}%'.format(NBAcc2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1d708",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e04d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreListDT = []\n",
    "for i in range(2,21):\n",
    "    DTclassifier = DecisionTreeClassifier(max_leaf_nodes=i)\n",
    "    DTclassifier.fit(X_train, y_train)\n",
    "    scoreListDT.append(DTclassifier.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(range(2,21), scoreListDT)\n",
    "plt.xticks(np.arange(2,21,1))\n",
    "plt.xlabel(\"Leaf\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "DTAcc = max(scoreListDT)\n",
    "print(\"Decision Tree Accuracy: {:.2f}%\".format(DTAcc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d04b59",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'Model': ['Logistic Regression', 'K Neighbors', 'Gaussian NB',\n",
    "                                  'Decision Tree', 'Random Forest'], \n",
    "                        'Accuracy': [LRAcc*100, KNAcc*100, NBAcc2*100, \n",
    "                                    DTAcc*100, RFAcc*100]})\n",
    "compare.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgAccuracy= pd.read_csv('data/ModelAccuracyAvg.csv')\n",
    "avgAccuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
